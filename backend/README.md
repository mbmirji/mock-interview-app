# Mock Interview API - Backend

FastAPI backend for the Mock Interview application with Supabase PostgreSQL and OpenAI integration.

---

## ğŸš€ Quick Start

### Local Development

```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Set up environment
cp .env.example .env
# Edit .env with your configuration

# 3. Create database tables
python create_tables.py

# 4. Run development server
uvicorn app.main:app --reload
```

Visit: http://localhost:8000/docs

---

## ğŸ“¦ Tech Stack

- **Framework**: FastAPI 0.109.0
- **Database**: PostgreSQL (Supabase)
- **ORM**: SQLAlchemy 2.0
- **LLM**: OpenAI GPT-4 / GPT-3.5 Turbo
- **Deployment**: Railway
- **Document Processing**: PyPDF2, python-docx, pdfplumber

---

## ğŸ—‚ï¸ Project Structure

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py              # FastAPI application entry
â”‚   â”œâ”€â”€ config.py            # Configuration settings
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ endpoints/
â”‚   â”‚       â””â”€â”€ __init__.py  # API endpoints
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ __init__.py      # SQLAlchemy models
â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â””â”€â”€ __init__.py      # Pydantic schemas
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ __init__.py      # LLM service
â”‚   â””â”€â”€ database/
â”‚       â””â”€â”€ __init__.py      # Database configuration
â”œâ”€â”€ .env.example             # Environment template
â”œâ”€â”€ .env.development         # Dev environment
â”œâ”€â”€ .env.production          # Prod environment
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ Procfile                 # Railway deployment
â”œâ”€â”€ railway.json             # Railway configuration
â”œâ”€â”€ create_tables.py         # Database initialization
â””â”€â”€ DEPLOYMENT_GUIDE.md      # Deployment instructions
```

---

## ğŸ—„ï¸ Database Schema

### Users
- User authentication and profiles
- Relationships: One-to-many with interview sessions

### Interview Sessions
- Mock interview attempts
- Stores resume and job description
- Tracks session status and statistics

### Interview Questions
- Individual Q&A within sessions
- LLM-generated questions and answers
- User responses and scoring

See [models/__init__.py](app/models/__init__.py) for full schema.

---

## ğŸ”§ Configuration

### Environment Variables

```bash
# Application
ENVIRONMENT=development  # development, staging, production
DEBUG=true
PORT=8000

# Supabase Database
DATABASE_URL=postgresql://postgres:password@host:5432/postgres

# OpenAI
OPENAI_API_KEY=sk-your-api-key
OPENAI_MODEL=gpt-4  # or gpt-3.5-turbo

# File Upload
MAX_FILE_SIZE_MB=10
```

### Configuration Files
- `.env` - Your local config (git-ignored)
- `.env.example` - Template with all options
- `.env.development` - Development defaults
- `.env.production` - Production settings

---

## ğŸ“¡ API Endpoints

### Upload Documents
```http
POST /api/v1/upload
Content-Type: multipart/form-data

Files:
- resume: PDF/DOC/DOCX
- job_description: PDF/DOC/DOCX

Response: Interview session with generated questions
```

### Get All Interviews
```http
GET /api/v1/interviews
Response: List of all interview sessions
```

### Get Interview by ID
```http
GET /api/v1/interviews/{id}
Response: Specific interview session
```

### Get Interview Questions
```http
GET /api/v1/interviews/{id}/questions
Response: Questions and answers for session
```

See interactive API docs at `/docs` when running.

---

## ğŸš¢ Deployment

### Railway + Supabase

1. **Set up Supabase**:
   - Create project at [supabase.com](https://supabase.com)
   - Get DATABASE_URL from Settings â†’ Database

2. **Deploy to Railway**:
   - Push code to GitHub
   - Import repo to [railway.app](https://railway.app)
   - Add environment variables
   - Deploy!

See [DEPLOYMENT_GUIDE.md](DEPLOYMENT_GUIDE.md) for detailed instructions.

---

## ğŸ§ª Testing

### Test Database Connection
```bash
python -c "from app.database import engine; engine.connect(); print('âœ“ Connected')"
```

### Test OpenAI Integration
```bash
python -c "from app.services import get_llm_service; svc = get_llm_service(); print('âœ“ LLM Ready')"
```

### Run API Tests
```bash
# Install test dependencies
pip install pytest httpx

# Run tests
pytest
```

---

## ğŸ“ File Upload Validation

Supported formats:
- âœ… PDF (`.pdf`)
- âœ… Word 2007+ (`.docx`)
- âœ… Word 97-2003 (`.doc`)

Max file size: 10 MB (configurable)

Validation at [endpoints/__init__.py:12](app/api/endpoints/__init__.py#L12)

---

## ğŸ” Security

- âœ… File type validation
- âœ… File size limits
- âœ… Environment-based configuration
- âœ… SSL for database connections
- âš ï¸ TODO: Add authentication
- âš ï¸ TODO: Add rate limiting
- âš ï¸ TODO: Add CORS configuration

---

## ğŸ’° Cost Estimates

### Development (Local)
- Free with local PostgreSQL

### Production (Railway + Supabase)
- **Supabase Free**: $0/month (500 MB DB)
- **Railway Free**: $0-5/month ($5 credit)
- **OpenAI**: $5-50/month (usage-based)
- **Total**: ~$5-55/month

---

## ğŸ› ï¸ Development

### Install Dependencies
```bash
pip install -r requirements.txt
```

### Database Migrations
```bash
# Create tables
python create_tables.py

# TODO: Add Alembic for migrations
# alembic init alembic
# alembic revision --autogenerate -m "Initial"
# alembic upgrade head
```

### Code Style
```bash
# Format code
black app/

# Lint
flake8 app/
```

---

## ğŸ› Troubleshooting

### Database Connection Issues
```bash
# Check connection string format
echo $DATABASE_URL

# Test connection
python -c "from app.database import engine; engine.connect()"
```

### OpenAI API Errors
- Verify API key is valid
- Check account has credits
- Try `gpt-3.5-turbo` instead of `gpt-4`

### Railway Deployment
- Ensure `Procfile` exists
- Check `railway.json` configuration
- View logs in Railway dashboard

---

## ğŸ“š Resources

- **FastAPI Docs**: https://fastapi.tiangolo.com
- **SQLAlchemy Docs**: https://docs.sqlalchemy.org
- **Supabase Docs**: https://supabase.com/docs
- **Railway Docs**: https://docs.railway.app
- **OpenAI API**: https://platform.openai.com/docs

---

## ğŸ“„ License

MIT License - see LICENSE file for details

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

---

## ğŸ“§ Support

For issues and questions:
- Open an issue on GitHub
- Check [DEPLOYMENT_GUIDE.md](DEPLOYMENT_GUIDE.md)
- Review API docs at `/docs`

---

**Built with â¤ï¸ using FastAPI, Supabase, and OpenAI**
